{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from nltk.corpus import stopwords\n",
    "from pymongo import MongoClient\n",
    "from scipy.ndimage import gaussian_gradient_magnitude\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "plt.style.use(\"seaborn-colorblind\")\n",
    "plt.rcParams[\"axes.axisbelow\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conn = MongoClient(\"localhost\", 27017)\n",
    "db = conn.get_database(\"nl_words\")\n",
    "videos_coll = db.get_collection(\"videos\")\n",
    "trans_coll = db.get_collection(\"transcripts\")\n",
    "transcripts = trans_coll.find({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Main stuff here\n",
    "\n",
    "main_df = pd.DataFrame(data=transcripts)\n",
    "main_df[\"word_count_mean_by_year\"] = main_df.groupby(main_df[\"date\"].dt.year)[\"word_count\"].transform(\"mean\")\n",
    "total_videos = len(main_df)\n",
    "total_unique_dates = len(main_df[\"date\"].unique())\n",
    "total_transcripts = len(main_df[main_df[\"text\"].notnull()])\n",
    "total_words = main_df[\"word_count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Solo stuff here\n",
    "\n",
    "exclude_string = \"nlss|team unity|northernlion live super show|roundtable|mathas|blood bowl\" \\\n",
    "                 \"carry dan|champions of salt|multiplayer|geoguessr|with friends|factorio|\" \\\n",
    "                 \"tournament|and friends|and sinvicta|and ohmwrecker|with dangheesling|\" \\\n",
    "                 \"w/ dangheesling|rocket league|podcast|speed bowl|spy vs spy|tutty|teaam unity\"\n",
    "\n",
    "solo_df = main_df[~main_df[\"title\"].str.contains(exclude_string, flags=re.IGNORECASE)]\n",
    "solo_df[\"word_count_mean_by_year\"] = solo_df.groupby(solo_df[\"date\"].dt.year)[\"word_count\"].transform(\"mean\")\n",
    "total_solo_videos = len(solo_df)\n",
    "total_solo_unique_dates = len(solo_df[\"date\"].unique())\n",
    "total_solo_transcripts = len(solo_df[main_df[\"text\"].notnull()])\n",
    "total_solo_words = solo_df[\"word_count\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Isaac stuff here\n",
    "\n",
    "isaac_df = main_df[main_df[\"title\"].str.contains(\"binding of isaac\", flags=re.IGNORECASE)]\n",
    "isaac_df[\"word_count_mean_by_year\"] = isaac_df.groupby(isaac_df[\"date\"].dt.year)[\"word_count\"].transform(\"mean\")\n",
    "total_isaac_videos = len(isaac_df)\n",
    "total_isaac_unique_dates = len(isaac_df[\"date\"].unique())\n",
    "total_isaac_transcripts = len(isaac_df[main_df[\"text\"].notnull()])\n",
    "total_isaac_words = isaac_df[\"word_count\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Date Range: 09/22/2010 to 02/20/2020\n",
    "\n",
    "Channel Totals:\n",
    "\n",
    "* Total videos: 11,087\n",
    "* Unique Dates: 11,032\n",
    "* Videos w/ Transcripts: 8,713\n",
    "* Total Words: 51,718,622\n",
    "\n",
    "Summary:\n",
    "\n",
    "|---|Word Count (per video)|\n",
    "|---|---|\n",
    "|Minimum|32|\n",
    "|25%|3,749|\n",
    "|Median|5,104|\n",
    "|Mean|5,935.80|\n",
    "|75%|6,639|\n",
    "|Maximum|34,845|\n",
    "|Std|4,445.04|\n",
    "\n",
    "Solo Totals\n",
    "\n",
    "* Total videos: 8,624\n",
    "* Unique Dates: 8,595\n",
    "* Videos w/ Transcripts: 7,127\n",
    "* Total Words: 38,087,400\n",
    "\n",
    "Summary:\n",
    "\n",
    "|---|Word Count (per video)|\n",
    "|---|---|\n",
    "|Minimum|32|\n",
    "|25%|3,979.50|\n",
    "|Median|5,258|\n",
    "|Mean|5,344.10|\n",
    "|75%|6,614|\n",
    "|Maximum|22,603|\n",
    "|Std|2,187.43|\n",
    "\n",
    "*Because of course...*\n",
    "\n",
    "Isaac Totals\n",
    "\n",
    "* Total videos: 3,431\n",
    "* Unique Dates: 3,431\n",
    "* Videos w/ Transcripts: 2,922\n",
    "* Total Words: 19,059,293\n",
    "\n",
    "Summary:\n",
    "\n",
    "|---|Word Count (per video)|\n",
    "|---|---|\n",
    "|Minimum|1,689|\n",
    "|25%|5,330|\n",
    "|Median|6,289|\n",
    "|Mean|6,522.69|\n",
    "|75%|7,494|\n",
    "|Maximum|16,154|\n",
    "|Std|1,724.30|\n",
    "\n",
    "Word Distribution (using solo transcripts)\n",
    "\n",
    "* Total Words (before stopwords): 38,087,400\n",
    "* Total Words (after stopwords): 11,413,612\n",
    "* Unique Words (before stopwords): 138,290\n",
    "* Unique Words (after stopwords): 106,156\n",
    "\n",
    "Top 20 Words:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 36000, 50)\n",
    "plt.figure(figsize=(11, 11))\n",
    "plt.grid(alpha=0.5)\n",
    "plt.hist(main_df[\"word_count\"], bins, alpha=0.75, edgecolor=\"black\", label=\"all\")\n",
    "plt.hist(solo_df[\"word_count\"], bins, alpha=0.75, edgecolor=\"black\", label=\"solo\")\n",
    "plt.hist(isaac_df[\"word_count\"], bins, alpha=0.75, edgecolor=\"black\", label=\"isaac\")\n",
    "plt.legend(loc=\"upper right\", prop={\"size\": 15})\n",
    "plt.title(\"Comparative Histogram: Word Counts of All Vids, Solo Vids, Isaac Vids\", fontsize=16, pad=10)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.ylabel(\"Occurrences\", fontsize=14, labelpad=20)\n",
    "plt.xlabel(\"Word Count\", fontsize=14, labelpad=20)\n",
    "plt.savefig(\"histogram.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_time_df = main_df.groupby(main_df[\"date\"].dt.year).first()\n",
    "solo_time_df = solo_df.groupby(solo_df[\"date\"].dt.year).first()\n",
    "isaac_time_df = isaac_df.groupby(isaac_df[\"date\"].dt.year).first()\n",
    "\n",
    "plt.figure(figsize=(11, 11))\n",
    "plt.grid(alpha=0.5)\n",
    "plt.plot_date(main_time_df[\"date\"], main_time_df[\"word_count_mean_by_year\"], marker=\"^\", linestyle=\"-\", alpha=0.75, label=\"channel\")\n",
    "plt.plot_date(solo_time_df[\"date\"], solo_time_df[\"word_count_mean_by_year\"], marker=\"*\", linestyle=\"-\", alpha=0.75, label=\"solo\")\n",
    "plt.plot_date(isaac_time_df[\"date\"], isaac_time_df[\"word_count_mean_by_year\"], marker=\".\", linestyle=\"-\", alpha=0.75, label=\"isaac\")\n",
    "plt.legend(loc=\"upper right\", prop={\"size\": 15})\n",
    "plt.title(\"Mean Word Counts by Year\", fontsize=16, pad=10)\n",
    "plt.tick_params(labelsize=12)\n",
    "plt.ylabel(\"Word Count\", fontsize=14, labelpad=20)\n",
    "plt.xlabel(\"Year\", fontsize=14, labelpad=20)\n",
    "plt.savefig(\"word_counts_by_year.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [0, np.pi/2, np.pi, 3 * np.pi/2]\n",
    "radii = [100, total_solo_words/total_words * 100, total_isaac_words/total_words * 100, (total_words - total_solo_words)/total_words * 100]\n",
    "width = np.pi/2\n",
    "fig = plt.figure(figsize=(11, 11))\n",
    "ax = plt.subplot(111, projection='polar')\n",
    "ax.bar(theta, radii, width=width, color=sns.color_palette(\"colorblind\", 4), alpha=0.75)\n",
    "ax.set_ylim(top=100)\n",
    "ax.get_ygridlines()[4].set_linewidth(2)\n",
    "ax.get_ygridlines()[4].set_color(\"black\")\n",
    "ax.spines[\"polar\"].set_visible(False)\n",
    "ax.set_title(\"Proportion Comparison of Word Counts\", fontsize=16, pad=10)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_rticks([20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_rlabel_position(20)\n",
    "ax.text(np.pi/8, 8, \"20%\", color=\"white\", fontsize=12)\n",
    "ax.text(np.pi/8, 25, \"40%\", color=\"white\", fontsize=12)\n",
    "ax.text(np.pi/8, 45, \"60%\", color=\"white\", fontsize=12)\n",
    "ax.text(np.pi/8, 65, \"80%\", color=\"white\", fontsize=12)\n",
    "ax.text(np.pi/8, 85, \"100%\", color=\"white\", fontsize=12)\n",
    "channel_patch = mpatches.Patch(color=sns.color_palette(\"colorblind\", 4)[0], label=\"channel\")\n",
    "solo_patch = mpatches.Patch(color=sns.color_palette(\"colorblind\", 4)[1], label=\"solo\")\n",
    "isaac_patch = mpatches.Patch(color=sns.color_palette(\"colorblind\", 4)[2], label=\"isaac\")\n",
    "collab_patch = mpatches.Patch(color=sns.color_palette(\"colorblind\", 4)[3], label=\"collab\")\n",
    "ax.legend(handles=[channel_patch, solo_patch, isaac_patch, collab_patch], loc=\"upper right\", bbox_to_anchor=(1.07, 1.06), prop={\"size\": 15})\n",
    "fig.savefig(\"proportion_comparison.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "with open(\"Stop_Words.txt\", \"r\") as file:\n",
    "    custom_stop_words = set(file.read().splitlines())\n",
    "    \n",
    "stop_words = stop_words.union(custom_stop_words)\n",
    "stop_words.add(\"gonna\")\n",
    "\n",
    "solo_word_dist = {}\n",
    "\n",
    "for i, row in solo_df.iterrows():\n",
    "    if row.get(\"words\"):\n",
    "        for word in row[\"words\"]:\n",
    "            word = word.lower()\n",
    "            if solo_word_dist.get(word, None):\n",
    "                solo_word_dist[word] += 1\n",
    "            else:\n",
    "                solo_word_dist[word] = 1\n",
    "                \n",
    "sorted_solo_word_dist = {k: v for k, v in sorted(solo_word_dist.items(), key=lambda x: x[1], reverse=True)}\n",
    "solo_initial_num_words = len(list(solo_word_dist.keys()))\n",
    "\n",
    "for word in stop_words:\n",
    "    if word in sorted_solo_word_dist:\n",
    "        sorted_solo_word_dist.pop(word)\n",
    "        \n",
    "solo_final_num_words = len(list(sorted_solo_word_dist.keys()))\n",
    "total_solo_final_words = sum(list(sorted_solo_word_dist.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(solo_initial_num_words)\n",
    "print(solo_final_num_words)\n",
    "print(total_solo_final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_solo_word_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 11))\n",
    "ax.bar(range(20), list(sorted_solo_word_dist.values())[:20], align=\"center\", color=sns.color_palette(\"colorblind\", 5), \n",
    "       alpha=0.75)\n",
    "ax.grid(alpha=0.5, axis=\"y\")\n",
    "ax.set_xticks(range(20))\n",
    "ax.set_yticklabels([str(x) for x in range(0, 160000, 20000)], fontsize=14)\n",
    "ax.set_xticklabels(list(sorted_solo_word_dist.keys())[:20], rotation=\"vertical\", fontsize=14)\n",
    "ax.set_title(\"Solo Videos Top 20 Words\", fontsize=16, pad=10)\n",
    "for i, value in enumerate(list(sorted_solo_word_dist.values())[:20]):\n",
    "    ax.text(i, 3000, f\"{value:,}\", color=\"white\", rotation=\"vertical\", horizontalalignment=\"center\", fontweight=\"bold\", \n",
    "            fontsize=12)\n",
    "ax.yaxis.get_label().set_fontsize(14)\n",
    "fig.savefig(\"solo_top_20.pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logo_color = np.array(Image.open(\"logo.jpg\"))\n",
    "logo_mask = logo_color.copy()\n",
    "edges = np.mean([gaussian_gradient_magnitude(logo_color[:, :, i] / 50., 3) for i in range(3)], axis=0)\n",
    "logo_mask[edges > .09] = 0\n",
    "\n",
    "wordcloud = WordCloud(max_words=8000, mask=logo_mask, max_font_size=30, random_state=40, relative_scaling=0).generate_from_frequencies(frequencies=sorted_solo_word_dist)\n",
    "wordcloud_colors = ImageColorGenerator(logo_color)\n",
    "wordcloud.recolor(color_func=wordcloud_colors)\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud.png\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}